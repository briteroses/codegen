05/08/2023 22:32:48 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False
05/08/2023 22:32:48 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='models/retriever/docprompting_enhanced_python_doc_retriever', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=512, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='logs', logging_first_step=False, logging_steps=1, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=125, dataloader_num_workers=0, past_index=-1, run_name='docprompting_enhanced_python_doc_retriever', disable_tqdm=True, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='recall@10', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False, customized_eval=True, customized_eval_used_split='dev', tmp_tag='tmp', report_to='wandb', eval_form='retrieval', eval_retriever='t5', eval_src_file='data/conala-modified/conala_nl_modified.txt', eval_tgt_file='data/conala/python_manual_firstpara.tok.txt', eval_root_folder='data/conala-modified', eval_oracle_file='data/conala-modified/cmd_dev.oracle_man.full_modified.json')
05/08/2023 22:32:48 - WARNING - datasets.builder -   Found cached dataset json (/mnt/xfs/home/branhung/.cache/huggingface/datasets/json/default-c591c4b8088d3d2d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.75it/s]100%|██████████| 1/1 [00:00<00:00,  2.75it/s]
[INFO|configuration_utils.py:445] 2023-05-08 22:32:49,053 >> loading configuration file https://huggingface.co/Salesforce/codet5-base/resolve/main/config.json from cache at /mnt/xfs/home/branhung/.cache/huggingface/transformers/f1adf9032ebe26d0dd0b9c4917416e2db960b7e8b8e68f0612e8e5d5379488f5.20220fde7ff6c94c24bdcd615678f6a4374f3176abdc061beecc43a906725837
[INFO|configuration_utils.py:481] 2023-05-08 22:32:49,054 >> Model config T5Config {
  "_name_or_path": "/content/drive/MyDrive/CodeT5/pretrained_models/codet5_base",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "bos_token_id": 1,
  "d_ff": 3072,
  "d_kv": 64,
  "d_model": 768,
  "decoder_start_token_id": 0,
  "dropout_rate": 0.1,
  "eos_token_id": 2,
  "feed_forward_proj": "relu",
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 12,
  "num_heads": 12,
  "num_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.2.1",
  "use_cache": true,
  "vocab_size": 32100
}

[INFO|tokenization_utils_base.py:1682] 2023-05-08 22:32:49,054 >> Model name 'Salesforce/codet5-base' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'Salesforce/codet5-base' is a path, a model identifier, or url to a directory containing tokenizer files.
[INFO|tokenization_utils_base.py:1766] 2023-05-08 22:32:49,307 >> loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/vocab.json from cache at /mnt/xfs/home/branhung/.cache/huggingface/transformers/1e2aacf615bc83f25a9d748eccb762b335eee01a29ab7a8db9b8e86cc851d489.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805
[INFO|tokenization_utils_base.py:1766] 2023-05-08 22:32:49,308 >> loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/merges.txt from cache at /mnt/xfs/home/branhung/.cache/huggingface/transformers/7eaa9b856402f05e8fdd452951872ecd3c2692ea9abb86b7ab62b07e3bc5f7de.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3
[INFO|tokenization_utils_base.py:1766] 2023-05-08 22:32:49,308 >> loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1766] 2023-05-08 22:32:49,308 >> loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/added_tokens.json from cache at /mnt/xfs/home/branhung/.cache/huggingface/transformers/a3e93db547e41cdd21f01826d07c5679e111b02d8e969c607611c30a6acbe191.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b
[INFO|tokenization_utils_base.py:1766] 2023-05-08 22:32:49,308 >> loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/special_tokens_map.json from cache at /mnt/xfs/home/branhung/.cache/huggingface/transformers/5941df5e4315c5ab63b7b2ac791fb0bf0f209744a055c06b43b5274849137cdd.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f
[INFO|tokenization_utils_base.py:1766] 2023-05-08 22:32:49,308 >> loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/tokenizer_config.json from cache at /mnt/xfs/home/branhung/.cache/huggingface/transformers/c99468017f7cb1b243c80a5640fd483688c5ec58bcd18b64efa5b82d8df7bc24.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2
[INFO|configuration_utils.py:445] 2023-05-08 22:32:49,416 >> loading configuration file https://huggingface.co/Salesforce/codet5-base/resolve/main/config.json from cache at /mnt/xfs/home/branhung/.cache/huggingface/transformers/f1adf9032ebe26d0dd0b9c4917416e2db960b7e8b8e68f0612e8e5d5379488f5.20220fde7ff6c94c24bdcd615678f6a4374f3176abdc061beecc43a906725837
[INFO|configuration_utils.py:481] 2023-05-08 22:32:49,416 >> Model config T5Config {
  "_name_or_path": "/content/drive/MyDrive/CodeT5/pretrained_models/codet5_base",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "bos_token_id": 1,
  "d_ff": 3072,
  "d_kv": 64,
  "d_model": 768,
  "decoder_start_token_id": 0,
  "dropout_rate": 0.1,
  "eos_token_id": 2,
  "feed_forward_proj": "relu",
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 12,
  "num_heads": 12,
  "num_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.2.1",
  "use_cache": true,
  "vocab_size": 32100
}

[INFO|modeling_utils.py:1027] 2023-05-08 22:32:49,457 >> loading weights file https://huggingface.co/Salesforce/codet5-base/resolve/main/pytorch_model.bin from cache at /mnt/xfs/home/branhung/.cache/huggingface/transformers/1afeeca5d5f5a78dca99d501138e9d6ffc6ff52d8048459ca67b3752e7b4d325.200e87e8e909da91038103a5ef6266da8d95a33855e53ec2031712515063c45c
[WARNING|modeling_utils.py:1134] 2023-05-08 22:32:52,105 >> Some weights of the model checkpoint at Salesforce/codet5-base were not used when initializing T5EncoderModel: ['decoder.embed_tokens.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'lm_head.weight']
- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1151] 2023-05-08 22:32:52,105 >> All the weights of T5EncoderModel were initialized from the model checkpoint at Salesforce/codet5-base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use T5EncoderModel for predictions without further training.
05/08/2023 22:32:53 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /mnt/xfs/home/branhung/.cache/huggingface/datasets/json/default-c591c4b8088d3d2d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-24cd72985ba608bf.arrow
[WARNING|integrations.py:491] 2023-05-08 22:32:54,336 >> W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.
05/08/2023 22:32:54 - INFO - simcse.trainers -   ***** Running training *****
05/08/2023 22:32:54 - INFO - simcse.trainers -     Num examples = 768777
05/08/2023 22:32:54 - INFO - simcse.trainers -     Num Epochs = 10
05/08/2023 22:32:54 - INFO - simcse.trainers -     Instantaneous batch size per device = 512
05/08/2023 22:32:54 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 512
05/08/2023 22:32:54 - INFO - simcse.trainers -     Gradient Accumulation steps = 1
05/08/2023 22:32:54 - INFO - simcse.trainers -     Total optimization steps = 15020
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:03,  6.37it/s]  8%|▊         | 2/25 [00:00<00:03,  6.48it/s] 12%|█▏        | 3/25 [00:00<00:03,  6.78it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.22it/s] 20%|██        | 5/25 [00:00<00:03,  6.53it/s] 24%|██▍       | 6/25 [00:00<00:02,  6.98it/s] 28%|██▊       | 7/25 [00:01<00:02,  7.22it/s] 32%|███▏      | 8/25 [00:01<00:02,  7.40it/s] 36%|███▌      | 9/25 [00:01<00:02,  7.35it/s] 40%|████      | 10/25 [00:01<00:02,  7.31it/s] 44%|████▍     | 11/25 [00:01<00:02,  6.85it/s] 48%|████▊     | 12/25 [00:01<00:01,  6.98it/s] 52%|█████▏    | 13/25 [00:01<00:01,  6.67it/s] 56%|█████▌    | 14/25 [00:02<00:01,  6.81it/s] 60%|██████    | 15/25 [00:02<00:01,  7.07it/s] 64%|██████▍   | 16/25 [00:02<00:01,  6.90it/s] 68%|██████▊   | 17/25 [00:02<00:01,  6.78it/s] 72%|███████▏  | 18/25 [00:02<00:01,  6.71it/s] 76%|███████▌  | 19/25 [00:02<00:00,  7.02it/s] 80%|████████  | 20/25 [00:02<00:00,  7.07it/s] 84%|████████▍ | 21/25 [00:03<00:00,  7.07it/s] 88%|████████▊ | 22/25 [00:03<00:00,  7.28it/s] 92%|█████████▏| 23/25 [00:03<00:00,  7.44it/s] 96%|█████████▌| 24/25 [00:03<00:00,  7.57it/s]100%|██████████| 25/25 [00:03<00:00,  7.23it/s]
  0%|          | 0/241 [00:00<?, ?it/s]  1%|          | 2/241 [00:00<00:15, 15.25it/s]  2%|▏         | 4/241 [00:00<00:15, 15.29it/s]  2%|▏         | 6/241 [00:00<00:16, 14.46it/s]  3%|▎         | 8/241 [00:00<00:15, 14.76it/s]  4%|▍         | 10/241 [00:00<00:15, 15.31it/s]  5%|▍         | 12/241 [00:00<00:14, 15.82it/s]  6%|▌         | 14/241 [00:00<00:14, 16.12it/s]  7%|▋         | 16/241 [00:01<00:13, 16.66it/s]  7%|▋         | 18/241 [00:01<00:13, 17.01it/s]  8%|▊         | 20/241 [00:01<00:13, 16.50it/s]  9%|▉         | 22/241 [00:01<00:14, 15.38it/s] 10%|▉         | 24/241 [00:01<00:14, 14.55it/s] 11%|█         | 26/241 [00:01<00:14, 14.45it/s] 12%|█▏        | 28/241 [00:01<00:14, 14.31it/s] 12%|█▏        | 30/241 [00:01<00:14, 14.63it/s] 13%|█▎        | 32/241 [00:02<00:13, 15.15it/s] 14%|█▍        | 34/241 [00:02<00:20, 10.23it/s] 15%|█▍        | 36/241 [00:02<00:30,  6.80it/s] 15%|█▌        | 37/241 [00:03<00:30,  6.77it/s] 16%|█▌        | 38/241 [00:03<00:34,  5.92it/s] 16%|█▌        | 39/241 [00:03<00:34,  5.80it/s] 17%|█▋        | 40/241 [00:03<00:34,  5.88it/s] 17%|█▋        | 41/241 [00:04<00:40,  4.95it/s] 17%|█▋        | 42/241 [00:04<00:38,  5.22it/s] 18%|█▊        | 43/241 [00:04<00:41,  4.82it/s] 18%|█▊        | 44/241 [00:04<00:37,  5.22it/s] 19%|█▊        | 45/241 [00:04<00:43,  4.50it/s] 19%|█▉        | 46/241 [00:04<00:37,  5.19it/s] 20%|█▉        | 47/241 [00:05<00:32,  5.90it/s] 20%|█▉        | 48/241 [00:05<00:32,  5.88it/s] 20%|██        | 49/241 [00:05<00:31,  6.02it/s] 21%|██        | 50/241 [00:05<00:32,  5.93it/s] 21%|██        | 51/241 [00:05<00:33,  5.71it/s] 22%|██▏       | 52/241 [00:05<00:32,  5.79it/s] 22%|██▏       | 53/241 [00:06<00:30,  6.17it/s] 22%|██▏       | 54/241 [00:06<00:28,  6.65it/s] 23%|██▎       | 56/241 [00:06<00:21,  8.52it/s] 24%|██▍       | 58/241 [00:06<00:17, 10.59it/s] 25%|██▍       | 60/241 [00:06<00:15, 12.06it/s] 26%|██▌       | 62/241 [00:06<00:13, 13.01it/s] 27%|██▋       | 64/241 [00:06<00:13, 12.72it/s] 27%|██▋       | 66/241 [00:07<00:13, 13.28it/s] 28%|██▊       | 68/241 [00:07<00:12, 13.64it/s] 29%|██▉       | 70/241 [00:07<00:11, 14.29it/s] 30%|██▉       | 72/241 [00:07<00:12, 13.37it/s] 31%|███       | 74/241 [00:07<00:16, 10.23it/s] 32%|███▏      | 76/241 [00:08<00:21,  7.74it/s] 32%|███▏      | 77/241 [00:08<00:25,  6.49it/s] 32%|███▏      | 78/241 [00:08<00:26,  6.24it/s] 33%|███▎      | 79/241 [00:08<00:29,  5.54it/s] 33%|███▎      | 80/241 [00:09<00:30,  5.28it/s] 34%|███▍      | 82/241 [00:09<00:23,  6.91it/s] 35%|███▍      | 84/241 [00:09<00:19,  8.22it/s] 36%|███▌      | 86/241 [00:09<00:16,  9.24it/s] 36%|███▌      | 87/241 [00:09<00:17,  8.79it/s] 37%|███▋      | 89/241 [00:09<00:14, 10.73it/s] 38%|███▊      | 91/241 [00:10<00:13, 10.99it/s] 39%|███▊      | 93/241 [00:10<00:14, 10.50it/s] 39%|███▉      | 95/241 [00:10<00:15,  9.67it/s] 40%|████      | 97/241 [00:10<00:13, 10.76it/s] 41%|████      | 99/241 [00:11<00:19,  7.27it/s] 41%|████▏     | 100/241 [00:11<00:19,  7.39it/s] 42%|████▏     | 101/241 [00:11<00:20,  6.82it/s] 42%|████▏     | 102/241 [00:11<00:21,  6.61it/s] 43%|████▎     | 103/241 [00:11<00:25,  5.31it/s] 43%|████▎     | 104/241 [00:12<00:29,  4.60it/s] 44%|████▎     | 105/241 [00:12<00:32,  4.17it/s] 44%|████▍     | 106/241 [00:12<00:31,  4.26it/s] 44%|████▍     | 107/241 [00:12<00:31,  4.20it/s] 45%|████▍     | 108/241 [00:13<00:36,  3.65it/s] 45%|████▌     | 109/241 [00:13<00:36,  3.62it/s] 46%|████▌     | 110/241 [00:13<00:35,  3.73it/s] 46%|████▌     | 111/241 [00:14<00:36,  3.61it/s] 46%|████▋     | 112/241 [00:14<00:31,  4.11it/s] 47%|████▋     | 113/241 [00:14<00:32,  3.93it/s] 47%|████▋     | 114/241 [00:14<00:33,  3.82it/s] 48%|████▊     | 115/241 [00:15<00:32,  3.86it/s] 48%|████▊     | 116/241 [00:15<00:35,  3.50it/s] 49%|████▊     | 117/241 [00:15<00:33,  3.65it/s] 49%|████▉     | 118/241 [00:15<00:32,  3.75it/s] 49%|████▉     | 119/241 [00:16<00:31,  3.81it/s] 50%|████▉     | 120/241 [00:16<00:30,  3.96it/s] 50%|█████     | 121/241 [00:16<00:30,  3.98it/s] 51%|█████     | 122/241 [00:16<00:27,  4.34it/s] 51%|█████     | 123/241 [00:17<00:27,  4.23it/s] 51%|█████▏    | 124/241 [00:17<00:30,  3.81it/s] 52%|█████▏    | 125/241 [00:17<00:27,  4.18it/s] 52%|█████▏    | 126/241 [00:17<00:31,  3.61it/s] 53%|█████▎    | 127/241 [00:18<00:28,  3.99it/s] 53%|█████▎    | 128/241 [00:18<00:27,  4.09it/s] 54%|█████▎    | 129/241 [00:18<00:30,  3.69it/s] 54%|█████▍    | 130/241 [00:18<00:28,  3.87it/s] 54%|█████▍    | 131/241 [00:19<00:25,  4.28it/s] 55%|█████▍    | 132/241 [00:19<00:25,  4.20it/s] 55%|█████▌    | 133/241 [00:19<00:25,  4.28it/s] 56%|█████▌    | 134/241 [00:19<00:26,  4.02it/s] 56%|█████▌    | 135/241 [00:20<00:25,  4.14it/s] 56%|█████▋    | 136/241 [00:20<00:31,  3.37it/s] 57%|█████▋    | 137/241 [00:20<00:30,  3.41it/s] 57%|█████▋    | 138/241 [00:21<00:28,  3.57it/s] 58%|█████▊    | 139/241 [00:21<00:36,  2.81it/s] 58%|█████▊    | 140/241 [00:22<00:36,  2.75it/s] 59%|█████▊    | 141/241 [00:22<00:37,  2.69it/s] 59%|█████▉    | 142/241 [00:22<00:32,  3.06it/s] 59%|█████▉    | 143/241 [00:22<00:28,  3.50it/s] 60%|█████▉    | 144/241 [00:23<00:27,  3.50it/s] 60%|██████    | 145/241 [00:23<00:25,  3.75it/s] 61%|██████    | 146/241 [00:23<00:26,  3.65it/s] 61%|██████    | 147/241 [00:23<00:25,  3.68it/s] 61%|██████▏   | 148/241 [00:24<00:23,  3.90it/s] 62%|██████▏   | 149/241 [00:24<00:25,  3.58it/s] 62%|██████▏   | 150/241 [00:24<00:29,  3.12it/s] 63%|██████▎   | 151/241 [00:25<00:25,  3.50it/s] 63%|██████▎   | 152/241 [00:25<00:22,  3.95it/s] 63%|██████▎   | 153/241 [00:25<00:23,  3.75it/s] 64%|██████▍   | 154/241 [00:25<00:22,  3.84it/s] 64%|██████▍   | 155/241 [00:25<00:20,  4.17it/s] 65%|██████▍   | 156/241 [00:26<00:22,  3.77it/s] 65%|██████▌   | 157/241 [00:26<00:21,  3.85it/s] 66%|██████▌   | 158/241 [00:26<00:21,  3.93it/s] 66%|██████▌   | 159/241 [00:26<00:18,  4.40it/s] 66%|██████▋   | 160/241 [00:27<00:19,  4.10it/s] 67%|██████▋   | 161/241 [00:27<00:18,  4.22it/s] 67%|██████▋   | 162/241 [00:27<00:21,  3.74it/s] 68%|██████▊   | 163/241 [00:28<00:22,  3.48it/s] 68%|██████▊   | 164/241 [00:28<00:18,  4.27it/s] 68%|██████▊   | 165/241 [00:28<00:15,  5.06it/s] 69%|██████▉   | 166/241 [00:28<00:13,  5.71it/s] 69%|██████▉   | 167/241 [00:28<00:12,  5.96it/s] 70%|██████▉   | 168/241 [00:28<00:11,  6.14it/s] 70%|███████   | 169/241 [00:28<00:11,  6.07it/s] 71%|███████   | 170/241 [00:29<00:11,  6.45it/s] 71%|███████   | 171/241 [00:29<00:10,  6.72it/s] 71%|███████▏  | 172/241 [00:29<00:10,  6.72it/s] 72%|███████▏  | 173/241 [00:29<00:10,  6.41it/s] 73%|███████▎  | 175/241 [00:29<00:08,  7.63it/s] 73%|███████▎  | 176/241 [00:29<00:08,  8.00it/s] 73%|███████▎  | 177/241 [00:29<00:07,  8.36it/s] 74%|███████▍  | 178/241 [00:30<00:07,  8.66it/s] 74%|███████▍  | 179/241 [00:30<00:06,  8.90it/s] 75%|███████▍  | 180/241 [00:30<00:06,  9.08it/s] 75%|███████▌  | 181/241 [00:30<00:06,  9.22it/s] 76%|███████▌  | 182/241 [00:30<00:06,  9.32it/s] 76%|███████▌  | 183/241 [00:30<00:06,  9.39it/s] 76%|███████▋  | 184/241 [00:30<00:06,  9.46it/s] 77%|███████▋  | 185/241 [00:30<00:05,  9.48it/s] 77%|███████▋  | 186/241 [00:30<00:05,  9.47it/s] 78%|███████▊  | 187/241 [00:31<00:06,  8.48it/s] 78%|███████▊  | 188/241 [00:31<00:06,  7.92it/s] 78%|███████▊  | 189/241 [00:31<00:06,  7.57it/s] 79%|███████▉  | 190/241 [00:31<00:06,  7.33it/s] 79%|███████▉  | 191/241 [00:31<00:07,  6.95it/s] 80%|███████▉  | 192/241 [00:31<00:06,  7.30it/s] 80%|████████  | 193/241 [00:31<00:07,  6.58it/s] 80%|████████  | 194/241 [00:32<00:06,  6.79it/s] 81%|████████  | 195/241 [00:32<00:07,  6.06it/s] 81%|████████▏ | 196/241 [00:32<00:07,  5.67it/s] 82%|████████▏ | 197/241 [00:32<00:07,  6.24it/s] 82%|████████▏ | 198/241 [00:32<00:06,  6.72it/s] 83%|████████▎ | 199/241 [00:32<00:06,  6.61it/s] 83%|████████▎ | 200/241 [00:33<00:06,  6.68it/s] 83%|████████▎ | 201/241 [00:33<00:05,  7.07it/s] 84%|████████▍ | 202/241 [00:33<00:05,  7.46it/s] 84%|████████▍ | 203/241 [00:33<00:05,  7.44it/s] 85%|████████▍ | 204/241 [00:33<00:05,  6.85it/s] 85%|████████▌ | 205/241 [00:33<00:05,  6.16it/s] 85%|████████▌ | 206/241 [00:33<00:05,  6.08it/s] 86%|████████▌ | 207/241 [00:34<00:05,  6.36it/s] 86%|████████▋ | 208/241 [00:34<00:05,  6.30it/s] 87%|████████▋ | 209/241 [00:34<00:05,  6.36it/s] 87%|████████▋ | 210/241 [00:34<00:04,  6.25it/s] 88%|████████▊ | 211/241 [00:34<00:05,  5.88it/s] 88%|████████▊ | 212/241 [00:35<00:05,  5.19it/s] 88%|████████▊ | 213/241 [00:35<00:05,  4.93it/s] 89%|████████▉ | 214/241 [00:35<00:05,  5.33it/s] 89%|████████▉ | 215/241 [00:35<00:04,  5.29it/s] 90%|████████▉ | 216/241 [00:35<00:05,  4.20it/s] 90%|█████████ | 217/241 [00:36<00:05,  4.55it/s] 90%|█████████ | 218/241 [00:36<00:04,  4.76it/s] 91%|█████████ | 219/241 [00:36<00:04,  5.27it/s] 91%|█████████▏| 220/241 [00:36<00:03,  5.57it/s] 92%|█████████▏| 221/241 [00:36<00:03,  5.69it/s] 92%|█████████▏| 222/241 [00:36<00:03,  5.75it/s] 93%|█████████▎| 223/241 [00:37<00:03,  5.56it/s] 93%|█████████▎| 224/241 [00:37<00:03,  5.65it/s] 94%|█████████▍| 226/241 [00:37<00:02,  6.26it/s] 94%|█████████▍| 227/241 [00:37<00:02,  6.45it/s] 95%|█████████▌| 229/241 [00:37<00:01,  7.80it/s] 95%|█████████▌| 230/241 [00:38<00:01,  7.84it/s] 96%|█████████▌| 231/241 [00:38<00:01,  6.34it/s] 96%|█████████▋| 232/241 [00:38<00:01,  6.42it/s] 97%|█████████▋| 233/241 [00:38<00:01,  7.09it/s] 97%|█████████▋| 234/241 [00:38<00:00,  7.49it/s] 98%|█████████▊| 235/241 [00:38<00:00,  7.07it/s] 98%|█████████▊| 236/241 [00:38<00:00,  6.40it/s] 98%|█████████▊| 237/241 [00:39<00:00,  6.73it/s] 99%|█████████▉| 238/241 [00:39<00:00,  7.02it/s]100%|█████████▉| 240/241 [00:39<00:00,  7.26it/s]100%|██████████| 241/241 [00:39<00:00,  6.09it/s]
Traceback (most recent call last):
  File "/mnt/xfs/home/branhung/src/robust-clip/codegen-llm/docprompting/retriever/simcse/run_train.py", line 220, in <module>
    main()
  File "/mnt/xfs/home/branhung/src/robust-clip/codegen-llm/docprompting/retriever/simcse/run_train.py", line 195, in main
    trainer.train(model_path=model_path)
  File "/mnt/xfs/home/branhung/src/robust-clip/codegen-llm/docprompting/retriever/simcse/trainers.py", line 539, in train
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch)
  File "/mnt/xfs/home/branhung/conda_envs/llm/lib/python3.9/site-packages/transformers/trainer.py", line 1004, in _maybe_log_save_evaluate
    metrics = self.evaluate()
  File "/mnt/xfs/home/branhung/src/robust-clip/codegen-llm/docprompting/retriever/simcse/trainers.py", line 169, in evaluate
    se.retrieve(eval_config.source_embed_save_file,
  File "/mnt/xfs/home/branhung/src/robust-clip/codegen-llm/docprompting/retriever/simcse/run_inference.py", line 117, in retrieve
    assert len(source_id_map) == source_embed.shape[0]
AssertionError
