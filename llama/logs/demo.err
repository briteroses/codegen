The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. 
The class this function is called from is 'LlamaTokenizer'.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:10<00:21, 10.83s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:20<00:10, 10.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:28<00:00,  9.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:28<00:00,  9.56s/it]
Token indices sequence length is longer than the specified maximum sequence length for this model (1580 > 512). Running this sequence through the model will result in indexing errors
/mnt/xfs/home/branhung/conda_envs/llm/lib/python3.9/site-packages/transformers/generation/utils.py:1253: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)
  warnings.warn(
