{k: (float(d2[k]) / d1[k]) for k in d2}
dict((k, float(d2[k]) / d1[k]) for k in d2)
testfile = urllib.request.URLopener() testfile.retrieve('http://randomsite.com/file.gz', 'file.gz')
urllib.request.urlretrieve('http://randomsite.com/file.gz', 'file.gz')
MyModel.objects.extra(where=['CHAR_LENGTH(text) > 254'])
((a and (not b)) or ((not a) and b))
(date(2010, 12, 31) + relativedelta(months=(+ 1)))
(date(2010, 12, 31) + relativedelta(months=(+ 2)))
subprocess.call('test1.py', shell=True)
hasattr(obj, 'attr_name')
list(grouper(2, [1, 2, 3, 4, 5, 6, 7]))
[input[i:i + n] for i in range(0, len(input), n)]
re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', s)
df.loc[df.groupby('User')['X'].transform(sum) == 0]
df.groupby('User')['X'].transform(sum) == 0
webbrowser.open('http://example.com')
os.environ['HOME']
os.environ['HOME']
print(os.environ)
os.environ
print(os.getenv('KEY_THAT_MIGHT_EXIST', default_value))
sorted(list(dictionary.items()), key=operator.itemgetter(1))
sorted(list(dictionary.items()), key=lambda x: x[1])
df['stats'].str[1:-1].str.split(',', expand=True).astype(float)
df['stats'].str[1:-1].str.split(',').apply(pd.Series).astype(float)
line.translate(None, '!@#$')
line = re.sub('[!@#$]', '', line)
string.replace('1', '')
line = line.translate(string.maketrans('', ''), '!@#$')
(t - datetime.timedelta(hours=1, minutes=10))
dt -= datetime.timedelta(hours=5)
random.randint(100000000000, 999999999999)
'%0.12d' % random.randint(0, 999999999999)
page = urllib.request.urlopen('http://www.google.com/') soup = BeautifulSoup(page)
root.lift()
'{:,}'.format(value)
ax.xaxis.set_label_position('top')
ax.xaxis.tick_top()
numpy.in1d(b, a).all()
list('{0:0b}'.format(8))
[int(x) for x in list('{0:0b}'.format(8))]
time.strftime('%Y-%m-%d %H:%M')
L[::(-1)]
L.reverse()
from subprocess import call
os.system('some_command with args')
os.system('some_command < input_file | another_command > output_file')
stream = os.popen('some_command with args')
return_code = subprocess.call('echo Hello World', shell=True)
call(['ls', '-l'])
os.path.realpath(__file__)
os.path.dirname(path)
os.path.realpath(path)
dir_path = os.path.dirname(os.path.realpath(__file__))
full_path = os.path.realpath(__file__)
struct.unpack('11B', s)
df['DateStr'] = df['DateObj'].dt.strftime('%d%m%Y')
print(list(itertools.product([1, 2, 3], [4, 5, 6])))
itertools.permutations([1, 2, 3])
df.to_csv('filename.csv', header=False)
root.destroy()
files = [f for f in os.listdir('.') if re.match('[0-9]+.*\\.jpg', f)]
df.pivot(index='order', columns='sample')
pickle.load(open('afile', 'rb'))
re.match('(.*?[.?!](?:\\s+.*?[.?!]){0,1})', phrase).group(1)
self.writer.writerow([str(s).encode('utf-8') for s in row])
data.set_index('Date').diff()
np.where(np.in1d(A, B))[0]
session.query(Task).filter(Task.time_spent > timedelta(hours=3)).all()
datetime.datetime.now()
datetime.datetime.now().time()
strftime('%Y-%m-%d %H:%M:%S', gmtime())
str(datetime.now())
datetime.datetime.time(datetime.datetime.now())
np.zeros((6, 9, 20)) + np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])[(None), :, (None)]
np.zeros((6, 9, 20)) + np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]).reshape((1, 9, 1))
pd.concat([df.head(1), df.tail(1)])
datetime.datetime.strptime('24052010', '%d%m%Y').date()
np.flatnonzero(x).mean()
a[tuple(b)]
tuple(map(int, input().split(',')))
tuple(int(x.strip()) for x in input().split(','))
ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)
df.groupby('STNAME')['COUNTY_POP'].agg(lambda x: x.nlargest(3).sum())
pd.pivot_table(df, index=df.index.date, columns=df.index.time, values='Close')
a.fromlist([int(val) for val in stdin.read().split()])
sorted(yourdata, reverse=True)
sorted(yourdata, key=lambda d: d.get('key', {}).get('subkey'), reverse=True)
yourdata.sort(key=lambda e: e['key']['subkey'], reverse=True)
networkx.draw_networkx_labels(G, pos, labels)
os.path.commonprefix(['/usr/var', '/usr/var2/log'])
print(os.path.relpath('/usr/var/log/', '/usr/var'))
getattr(getattr(myobject, 'id', None), 'number', None)
np.einsum('ij,kj->jik', X, X)
itertools.product(list(range(2)), repeat=4)
re.match('\\$[0-9]+[^\\$]*$', '$1 off delicious $5 ham.')
random.sample(range(1, 50), 6)
random.sample(range(1, 50), 6)
datetime.utcnow()
os.chdir('..')
canvas.create_text(x, y, font=('Purisa', 12), text=k)
pd.concat([pd.DataFrame(l) for l in my_list], axis=1).T
'one' in list(d.values())
'one' in iter(d.values())
pyplot.legend(loc=2, fontsize='x-small')
plot.legend(loc=2, prop={'size': 6})
sentence.replace(' ', '')
pattern = re.compile('\\s+') sentence = re.sub(pattern, '', sentence)
sentence.strip()
sentence = re.sub('\\s+', '', sentence, flags=re.UNICODE)
sentence = ''.join(sentence.split())
df1 = pd.read_hdf('/home/.../data.h5', 'firstSet')
str = open('very_Important.txt', 'r').read()
urlfetch.fetch(url, deadline=10 * 60)
urlparse.urldefrag('http://www.address.com/something#something')
sorted(iter(mydict.items()), key=itemgetter(1), reverse=True)
first_name = request.args.get('firstname')
first_name = request.form.get('firstname')
txt = open('file.txt').read()
(datetime.datetime.utcnow() - datetime.timedelta(hours=11)).year
Entry.objects.filter(~Q(id=3))
soup.find_all('div', class_='crBlock ')
struct.unpack('BBB', rgbstr.decode('hex'))
"""""".join(reversed([a[i:i + 2] for i in range(0, len(a), 2)]))
sys.exit()
quit()
sys.exit('some error message')
con.commit()
subprocess.check_output(['espeak', text], stderr=subprocess.STDOUT)
int(Decimal(s))
int(s.split('.')[0])
np.einsum('ijk,ikl->ijl', A, B)
subprocess.Popen(['rm', '-r', 'some.file'])
df.round({'Alabama_exp': 2, 'Credit_exp': 3})
e = next(iter(s))
dateobj = datetime.datetime.strptime(datestr, '%Y-%m-%d').date()
a = open('pdf_reference.pdf', 'rb').read().encode('base64')
os.chdir('chapter3')
os.chdir('C:\\Users\\username\\Desktop\\headfirstpython\\chapter3')
os.chdir('.\\chapter3')
br.form.add_file(open(filename), 'text/plain', filename)
re.match('[a-zA-Z][\\w-]*\\Z', 'A\n')
re.match('[a-zA-Z][\\w-]*$', '!A_B')
soup.find_all('div', class_=re.compile('comment-'))
plt.cla()
json.load(codecs.open('sample.json', 'r', 'utf-8-sig'))
json.loads(open('sample.json').read().decode('utf-8-sig'))
sys.exit(0)
struct.unpack('d', struct.pack('Q', int(s2, 0)))[0]
float(int('-0b1110', 0))
struct.unpack('d', b8)[0]
return user.groups.filter(name='Member').exists()
return user.groups.filter(name__in=['group1', 'group2']).exists()
np.where((vals == (0, 1)).all(axis=1))
os.chdir(os.path.dirname(__file__))
df.toPandas().to_csv('mycsv.csv')
df.write.csv('mycsv.csv')
zip(*[(1, 4), (2, 5), (3, 6)])
[list(group) for key, group in itertools.groupby(data, operator.itemgetter(1))]
df['a'].values.tolist()
df['a'].tolist()
soup = BeautifulSoup(response.read().decode('utf-8'))
a[np.arange(len(a)) != 3]
subprocess.check_output('echo "foo"', shell=True)
df['Date'].map(lambda t: t.date()).unique()
os.path.commonprefix(['/the/dir/', os.path.realpath(filename)]) == '/the/dir/'
dict(x[1:] for x in reversed(myListOfTuples))
list.sort(key=lambda item: item['date'], reverse=True)
df.to_csv('mydf.tsv', sep='\t')
Counter([1, 2, 2, 2, 3]) - Counter([1, 2])
difflib.SequenceMatcher(None, file1.read(), file2.read())
min(list, key=lambda x: float('inf') if math.isnan(x[1]) else x[1])
str_list = [tuple('{0:.8e}'.format(flt) for flt in sublist) for sublist in lst]
str_list = [['{0:.8e}'.format(flt) for flt in sublist] for sublist in lst]
A[[0, 1], [0, 1]]
a[np.arange(3), (0, 1, 0)]
soup.find_all(['a', 'div'])
'hello world'[::(-1)]
s[::(-1)]
''.join(reversed('foo'))
''.join(reversed(string))
'foo'[::(-1)]
a_string[::(-1)]
def reversed_string(a_string): return a_string[::(-1)]
''.join(reversed(s))
p = Popen(['grep', 'f'], stdout=PIPE, stdin=PIPE, stderr=STDOUT) grep_stdout = p.communicate(input='one\ntwo\nthree\nfour\nfive\nsix\n')[0]
p = subprocess.Popen(['grep', 'f'], stdout=subprocess.PIPE, stdin=subprocess.PIPE) p.stdin.write('one\ntwo\nthree\nfour\nfive\nsix\n') p.communicate()[0] p.stdin.close()
df.div(df.sum(axis=1), axis=0)
str(i)
a.__str__()
str(a)
result = sys.stdin.read()
A[np.all(np.any(A - B[:, (None)], axis=2), axis=0)]
df.query('index < @start_remove or index > @end_remove')
df.loc[(df.index < start_remove) | (df.index > end_remove)]
numpy.where(mask)
df.to_csv('Result.csv', index=False, sep=' ')
pd.DataFrame(d)
gzip.open('file.gz', 'rt', encoding='utf-8')
driver.get('http://www.google.com.br')
if ('blah' not in somestring): pass
string.find('substring')
if (s.find('is') == (-1)): print("No 'is' here!") else: print("Found 'is' in the string.")
globals()['myfunction']()
a.shape
N.shape(a)
N.shape(a)
a.shape
struct.unpack('f', struct.pack('f', 0.00582811585976))
[dict(y) for y in set(tuple(x.items()) for x in d)]
words = open('myfile').read().split()
a = np.array(a)
Blog.objects.filter(pk__in=[1, 4, 7])
if (string1.lower() == string2.lower()): print('The strings are the same (case insensitive)') else: print('The strings are not the same (case insensitive)')
if (string1.lower() == string2.lower()): pass
(string1.lower() == string2.lower())
(first.lower() == second.lower())
(first.upper() == second.upper())
pd.concat(map(pd.DataFrame, iter(d.values())), keys=list(d.keys())).stack().unstack(0)
df.groupby(['col5', 'col2']).size().groupby(level=1).max()
getattr(your_obj, x)
datetime.datetime.now().date()
datetime.datetime.now().date()
A = np.array(sorted(A, key=tuple))
s.lower()
s.decode('utf-8').lower()
session.query(User).filter_by(id=123).update({'name': 'Bob Marley'})
globals()['something'] = 'bob'
any(np.equal(a, [1, 2]).all(1))
np.zeros((3, 3)).ravel()
numpy.array([(key, val) for key, val in result.items()], dtype)
sys.exit(0)
mylist.sort(key=lambda x: x.lower())
mylist.sort(key=str.lower)
mylist.sort()
list.sort()
exec(compile(open('file.py').read(), 'file.py', 'exec'))
"""test.mp3""".endswith(('.mp3', '.avi'))
struct.unpack('h', pS[0:2])
print(all(word[0].isupper() for word in words))
df.to_sparse(0)
variable = []
intarray = array('i')
if hasattr(a, 'property'): pass
if hasattr(a, 'property'): pass
getattr(a, 'property', 'default value')
"""""".join(list(OrderedDict.fromkeys('aaabcabccd').keys()))
list(set('aaabcabccd'))
"""""".join(set('aaabcabccd'))
str.find('s', 16)
x.find('Aloha')
'sdfasdf'.index('cc')
'sdfasdf'.index('df')
str.find('a')
str.find('g')
str.find('s', 11)
str.find('s', 15)
str.find('s', 11, 14)
sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)
sorted(list(u.items()), key=lambda v: v[1])
sorted(list(d.items()), key=lambda k_v: k_v[1], reverse=True)
sorted(list(d.items()), key=lambda k_v: k_v[1])
sys.exit(0)
sys.exit('aa! errors!')
sys.exit()
datetime.datetime.now() - datetime.timedelta(days=1)
df = pd.DataFrame.from_dict({k: v for k, v in list(nvalues.items()) if k != 'y3'})
print(soup.find('a', href=re.compile('.*follow\\?page.*')))
np.mean(np.array([old_set, new_set]), axis=0)
bin(ord('P'))
{k for d in LoD for k in list(d.keys())}
set([i for s in [list(d.keys()) for d in LoD] for i in s])
[i for s in [list(d.keys()) for d in LoD] for i in s]
[int(d) for d in str(bin(x))[2:]]
df.groupby(['Month', 'Fruit']).sum().unstack(level=0)
requests.get('https://www.mysite.com/', auth=('username', 'pwd'))
[x for x in file.namelist() if x.endswith('/')]
str({'a': 1, 'b': 'as df'}).replace(': ', ':').replace(', ', ',')
'{' + ','.join('{0!r}:{1!r}'.format(*x) for x in list(dct.items())) + '}'
json_data = json.loads(json_string)
os.rename(src, dst)
window.set_position(Gtk.WindowPosition.CENTER)
self.request.get('var_name')
theset = set(k.lower() for k in thedict)
df2['revenue'] = df2.CET.map(df1.set_index('date')['revenue'])
os.chdir('C:/Users/Name/Desktop')
{{request.args.get('a')}}
os.stat('C:\\Python27\\Lib\\genericpath.py').st_size
urllib.parse.quote_plus('string_of_characters_like_these:$#@=?%^Q^$')
decimal.Decimal(random.randrange(10000)) / 100
os.path.basename(os.path.normpath('/folderA/folderB/folderC/folderD/'))
list(x.keys()).index('c')
[value for key, value in list(programs.items()) if 'new york' in key.lower()]
urllib.parse.quote(s.encode('utf-8'))
urllib.parse.quote_plus('a b')
df.groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum()
sum(((i > 5) for i in j))
len([1 for i in j if (i > 5)])
j = np.array(j) sum((j > i))
np.any(np.in1d(a1, a2))
max(min(my_value, max_value), min_value)
lst = list(itertools.product([0, 1], repeat=n))
lst = map(list, itertools.product([0, 1], repeat=n))
bin = [0, 1] [(x, y, z) for x in bin for y in bin for z in bin]
lst = list(itertools.product([0, 1], repeat=3))
datetime.datetime.now() + datetime.timedelta(days=1, hours=3)
struct.unpack('d', binascii.unhexlify('4081637ef7d0424a'))
plt.colorbar(im, ax=ax)
s[s.find('\n') + 1:s.rfind('\n')]
data.loc[:, (list(itertools.product(['one', 'two'], ['a', 'c'])))]
data.loc[:, ([('one', 'a'), ('one', 'c'), ('two', 'a'), ('two', 'c')])]
User.objects.filter(userprofile__level__gte=0)
[list(g) for _, g in itertools.groupby(test, lambda x: x.split('_')[0])]
[list(g) for _, g in itertools.groupby(test, lambda x: x.partition('_')[0])]
request.POST.get('title', '')
list(accumulate(list(range(10))))
json.loads(request.POST.get('mydata', '{}'))
max(test_string.rfind(i) for i in '([{')
"""foobar"""[:4]
s.rfind('&')
s[:s.rfind('&')]
ex.groupby(level='A').agg(lambda x: x.index.get_level_values(1).nunique())
numpy.array([[1, 2], [3, 4]])
t = tuple(x[0] for x in s)
soup.find('meta', {'name': 'City'})['content']
df.pivot_table(index='saleid', columns='upc', aggfunc='size', fill_value=0)
os.chmod(path, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)
df.to_csv(filename, date_format='%Y%m%d')
b = np.where(np.isnan(a), 0, a)
np.array([np.arange(3), np.arange(2, -1, -1), np.ones((3,))]).min(axis=0)
datetime.datetime.now().strftime('%a')
"""<br/>""".join([('%s:: %s' % (key, value)) for key, value in list(d.items())])
print(df.loc[df['A'] == 'foo'])
df.loc[df['column_name'] != some_value]
df.loc[~df['column_name'].isin(some_values)]
df.loc[df['column_name'] == some_value]
print(df.loc[df['B'].isin(['one', 'three'])])
help('modules')
s.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)
globals().update(importlib.import_module('some.package').__dict__)
numpy.where((x == 0))[0]
return HttpResponse(json.dumps(response_data), content_type='application/json')
s.decode('hex')
binascii.a2b_hex(s)
[(x + tuple(y)) for x, y in zip(zip(a, b), c)]
"""""".join('{}{}'.format(key, val) for key, val in sorted(adict.items()))
"""""".join('{}{}'.format(key, val) for key, val in list(adict.items()))
np.array(x._data).reshape(x.size[::-1]).T
hex(int(''.join([str(int(b)) for b in walls]), 2))
hex(sum(b << i for i, b in enumerate(reversed(walls))))
os.chdir('c:\\Users\\uname\\desktop\\python')
os.chdir(path)
urllib.request.urlopen('http://www.stackoverflow.com').getcode()
conn = httplib.HTTPConnection('www.python.org') conn.request('HEAD', '/') r1 = conn.getresponse() print(r1.status, r1.reason)
r = requests.head(url) return (r.status_code == 200)
print(urllib.request.urlopen('http://www.stackoverflow.com').getcode())
data.rename(columns={'gdp': 'log(gdp)'}, inplace=True)
dbb.commit()
{k: bigdict[k] for k in list(bigdict.keys()) & {'l', 'm', 'n'}}
dict((k, bigdict[k]) for k in ('l', 'm', 'n'))
{k: bigdict.get(k, None) for k in ('l', 'm', 'n')}
{k: bigdict[k] for k in ('l', 'm', 'n')}
json.load(u)
if ('blabla' in open('example.txt').read()): pass
f = open('example.txt') s = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) if (s.find('blabla') != (-1)): pass
datafile = file('example.txt') found = False for line in datafile: if (blabla in line): return True return False
r = requests.get(url)
r = requests.get(url, params=payload)
r = requests.post(url, data=payload)
post_response = requests.post(url='http://httpbin.org/post', json=post_data)
bin(173)
int('01010101111', 2)
int('010101', 2)
int('0b0010101010', 2)
bin(21)
int('11111111', 2)
(trace_df['ratio'] > 0).mean()
list(itertools.product(*a))
it = iter(sorted(d.items()))
for (key, value) in sorted(d.items()): pass
return sorted(dict.items())
return iter(sorted(dict.items()))
for (k, v) in sorted(foo.items()): pass
for k in sorted(foo.keys()): pass
re.sub('(?<=[a-z])([A-Z])', '-\\1', s).lower()
print(type(tf.Session().run(tf.constant([1, 2, 3]))))
s = pd.Series(['A', 'B', 'A1R', 'B2', 'AABB4'])
dict((x, set(y) & set(d1.get(x, ()))) for x, y in d2.items())
df = pandas.DataFrame(data, columns=['R_Number', 'C_Number', 'Avg', 'Std'])
pd.DataFrame(list(d.items()), columns=['Date', 'DateValue'])
numpy.random.choice(numpy.arange(1, 7), p=[0.1, 0.05, 0.05, 0.2, 0.4, 0.2])
df.set_index(['year', 'month', 'item']).unstack(level=-1)
df.pivot_table(values='value', index=['year', 'month'], columns='item')
p1.communicate()[0]
output = subprocess.Popen(['mycmd', 'myarg'], stdout=PIPE).communicate()[0]
[elem.tag for elem in a.iter()]
[elem.tag for elem in a.iter() if elem is not a]
min([x for x in num_list if x > 2])
a.remove('b')
a.remove(c)
a.remove(6)
a.remove(6)
if (c in a): a.remove(c)
try: a.remove(c) except ValueError: pass
subprocess.call('test.sh otherfunc')
subprocess.Popen(['bash', '-c', '. foo.sh; go'])
df.to_csv('c:\\data\\t.csv', index=False)
print(re.match('(\\d+(\\.\\d+)?)', '3434.35353').group(1))
Sample.objects.filter(date__range=['2011-01-01', '2011-01-31'])
Sample.objects.filter(date__year='2011', date__month='01')
img = Image.open('picture.jpg') img.show()
img = Image.open('picture.jpg') Img.show
f.write(open('xxx.mp4', 'rb').read())
pd.DataFrame(df.columns[np.argsort(df.values)], df.index, np.unique(df.values))
df1.groupby(['key', 'year']).size().reset_index()
df.groupby(np.arange(len(df.columns)) // 3, axis=1).mean()
redirect('Home.views.index')
sorted(list(things.keys()), key=lambda x: things[x]['weight'], reverse=True)
print(a_module.__file__)
print(os.getcwd())
path = os.path.abspath(amodule.__file__)
df.groupby(np.arange(len(df.columns)) // 2 + 1, axis=1).sum().add_prefix('s')
now = datetime.datetime.now().strftime('%H:%M:%S')
bytes.fromhex('4a4b4c').decode('utf-8')
subprocess.check_output('ps -ef | grep something | wc -l', shell=True)
pd.Series(list(set(s1).intersection(set(s2))))
then = datetime.datetime.strptime(when, '%Y-%m-%d').date()
Entry.objects.filter()[:1].get()
warnings.simplefilter('always')
urllib.request.urlretrieve('http://www.example.com/songs/mp3.mp3', 'mp3.mp3')
u = urllib.request.urlopen(url) f = open(file_name, 'wb') meta = u.info() file_size = int(meta.getheaders('Content-Length')[0]) print(('Downloading: %s Bytes: %s' % (file_name, file_size))) file_size_dl = 0 block_sz = 8192 while True: buffer = u.read(block_sz) if (not buffer): break file_size_dl += len(buffer) f.write(buffer) status = ('%10d [%3.2f%%]' % (file_size_dl, ((file_size_dl * 100.0) / file_size))) status = (status + (chr(8) * (len(status) + 1))) print(status, end=' ') f.close()
response = urllib.request.urlopen('http://www.example.com/') html = response.read()
r = requests.get(url)
response = requests.get(url, stream=True) with open('10MB', 'wb') as handle: for data in tqdm(response.iter_content()): handle.write(data)
scipy.tensordot(P, T, axes=[1, 1]).swapaxes(0, 1)
struct.unpack('!f', '470FC614'.decode('hex'))[0]
list(reversed(list(range(10))))
(datetime.datetime.now() - datetime.timedelta(days=7)).date()
base64.b64encode(bytes('your string', 'utf-8'))
[k for k, v in list(Counter(mylist).items()) if v > 1]
np.savetxt('c:\\data\\np.txt', df.values, fmt='%d')
df.to_csv('c:\\data\\pandas.txt', header=None, index=None, sep=' ', mode='a')
print(x.rpartition('-')[0])
print(x.rsplit('-', 1)[0])
[int(1000 * random.random()) for i in range(10000)]
datetime.datetime.now().strftime('%H:%M:%S.%f')
print('\n'.join('\t'.join(str(col) for col in row) for row in tab))
df.astype(bool).sum(axis=1)
re.sub('[^\\sa-zA-Z0-9]', '', text).lower().strip()
re.sub('(?!\\s)[\\W_]', '', text).lower().strip()
print(soup.find('name').string)
os.stat(filepath).st_size
l.count('a')
Counter(l)
[[x, l.count(x)] for x in set(l)]
dict(((x, l.count(x)) for x in set(l)))
l.count('b')
shutil.copy(srcfile, dstdir)
df['c'] = np.where(df['a'].isnull, df['b'], df['a'])
tuple(l)
level1 = map(list, level1)
pprint.pprint(dataobject, logFile)
df.loc[df['BoolCol']]
df.iloc[np.flatnonzero(df['BoolCol'])]
df[df['BoolCol'] == True].index.tolist()
df[df['BoolCol']].index.tolist()
os.chdir(owd)
soup.find('div', id='main-content').decompose()
np.array([zip(x, y) for x, y in zip(a, b)])
np.array(zip(a.ravel(), b.ravel()), dtype='i4,i4').reshape(a.shape)
'abcd}def}'.rfind('}')
np.random.shuffle(np.transpose(r))
os.statvfs('/').f_files - os.statvfs('/').f_ffree
cursor.fetchone()[0]
open('outfile', 'w').write('#test firstline\n' + open('infile').read())
bool(re.search('ba[rzd]', 'foobarrrr'))
list(set(t))
list(set(source_list))
list(OrderedDict.fromkeys('abracadabra'))
numpy.array(a).reshape(-1).tolist()
numpy.array(a)[0].tolist()
print(soup.find(text='Address:').findNext('td').contents[0])
encoded = base64.b64encode('data to be encoded')
encoded = 'data to be encoded'.encode('ascii')
getattr(my_object, my_str)
np.where(np.in1d(A, [1, 3, 4]).reshape(A.shape), A, 0)
np.mean(a, axis=1)
writer.writeheader()
a[np.where((a[:, (0)] == 0) * (a[:, (1)] == 1))]
pd.DataFrame({'email': sf.index, 'list': sf.values})
image = image.resize((x, y), Image.ANTIALIAS)
heapq.nlargest(10, range(len(l1)), key=lambda i: abs(l1[i] - l2[i]))
soup.find_all('span', {'class': 'starGryB sp'})
sorted(list5, lambda x: (degree(x), x))
sorted(list5, key=lambda vertex: (degree(vertex), vertex))
getattr(obj, 'attr')
json.dumps(Decimal('3.9'))
df.groupby('A').filter(lambda x: len(x) > 1)
plt.colorbar(mappable=mappable, cax=ax3)
Counter(' '.join(df['text']).split()).most_common(100)
datetime.now(pytz.utc)
return HttpResponse(data, mimetype='application/json')
subprocess.Popen(['background-process', 'arguments'])
[i for i, j in enumerate(myList) if 'how' in j.lower() or 'what' in j.lower()]
pd.DataFrame(out.tolist(), columns=['out-1', 'out-2'], index=out.index)
ax.set_xticklabels(labels, rotation=45)
len(list(yourdict.keys()))
len(set(open(yourdictfile).read().split()))
pd.concat([df[0].apply(pd.Series), df[1]], axis=1)
subprocess.Popen(['c:\\Program Files\\VMware\\VMware Server\\vmware-cmd.bat'])
q.put((-n, n))
print(concatenate((a, b), axis=0))
print(concatenate((a, b), axis=1))
c = np.r_[(a[None, :], b[None, :])]
np.array((a, b))
return HttpResponse('Unauthorized', status=401)
df.index.get_loc('bob')
np.column_stack(([1, 2, 3], [4, 5, 6]))
"""""".join([char for char in 'it is icy' if char != 'i'])
re.sub('i', '', 'it is icy')
"""it is icy""".replace('i', '')
"""""".join([char for char in 'it is icy' if char != 'i'])
nums = [int(x) for x in intstringlist]
map(int, eval(input('Enter the unfriendly numbers: ')))
os.chdir('/mydir') for file in glob.glob('*.txt'): pass
for file in os.listdir('/mydir'): if file.endswith('.txt'): pass
for (root, dirs, files) in os.walk('/mydir'): for file in files: if file.endswith('.txt'): pass
json.loads(request.body)
df.groupby('prots').sum().sort('scores', ascending=False)
json.load(urllib.request.urlopen('url'))
Entry.objects.filter(pub_date__contains='08:00')
list.sort(key=lambda item: (item['points'], item['time']))
struct.unpack('H', struct.pack('h', number))
df.to_csv(filename, index=False)
json_data = json.loads(unescaped)
newFile.write(struct.pack('5B', *newFileBytes))
list(dict.keys())[-1]
AuthorizedEmail.objects.filter(group=group).order_by('-added')[0]
datetime.datetime.now()
max(x.min(), x.max(), key=abs)
